{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMi/gpyjKM76EsFGWWZwSJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adilmar/Michelzinho-Gemini/blob/main/gemini_alura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importar as bibliotecas**"
      ],
      "metadata": {
        "id": "pnLLrQMACEYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "XoV594NFCJ4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Declarar variavel com a chave da api**"
      ],
      "metadata": {
        "id": "58zbx7FjCLAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = userdata.get('GEMINI')"
      ],
      "metadata": {
        "id": "lyv5-2PXCN9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6kuTSEe_jyK"
      },
      "outputs": [],
      "source": [
        "def gemini(api_key, text, objeto):\n",
        "  genai.configure(api_key=api_key)\n",
        "\n",
        "  # Set up the model\n",
        "  generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"stop_sequences\": [],\n",
        "  }\n",
        "\n",
        "  safety_settings = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "  ]\n",
        "\n",
        "  #aqui vai a instrucao para o seu chatbot\n",
        "  system_instruction = \"Voc√™ √© um chatbot chamado Michelzinho para crian√ßas com autismo, converse no mesmo tom. Voc√™ foi desenvolvido por Adilmar Coelho Dantas Doutor em Ci√™ncia da Computa√ß√£o  pela universidade federal de Uberl√¢ndia no ano de 2021. Voc√™ √© capaz de analisar a emo√ß√£o tamb√©m pela foto da crian√ßa. Seu site √© https://michelzinho.pushsistemas.com.br, voc√™ sabe falar sobre as emo√ß√µes para explicar como espessar e interpretar.\"\n",
        "\n",
        "  model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",generation_config=generation_config,system_instruction=system_instruction,safety_settings=safety_settings)\n",
        "\n",
        "  uploaded_files = []\n",
        "  def upload_if_needed(pathname: str) -> list[str]:\n",
        "    path = Path(pathname)\n",
        "    hash_id = hashlib.sha256(path.read_bytes()).hexdigest()\n",
        "    try:\n",
        "      existing_file = genai.get_file(name=hash_id)\n",
        "      return [existing_file.uri]\n",
        "    except:\n",
        "      pass\n",
        "    uploaded_files.append(genai.upload_file(path=path, display_name=hash_id))\n",
        "    return [uploaded_files[-1].uri]\n",
        "\n",
        "  convo = model.start_chat(history=objeto)\n",
        "\n",
        "  convo.send_message(text)\n",
        "\n",
        "  for uploaded_file in uploaded_files:\n",
        "    genai.delete_file(name=uploaded_file.name)\n",
        "\n",
        "  resposta = str(convo.last.text)\n",
        "\n",
        "  #gerando response em json\n",
        "  response = {\"StatusCode\":200, \"resposta\": resposta}\n",
        "\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historico = []\n",
        "\n",
        "mensagem = \"\"\n",
        "\n",
        "#condicao de repeticao para a conversa\n",
        "while mensagem != \"#sair\":\n",
        "  chat = str(input(\"üë§ Digite sua mensagem....\"))\n",
        "  mensagem = chat\n",
        "  historico.append({\"parts\":[chat],\"role\":\"user\"})\n",
        "  response = gemini(API_KEY,chat,historico)\n",
        "  resposta = str(response[\"resposta\"])\n",
        "  resposta = f\"üê∂ {resposta}\"\n",
        "  print(resposta)\n",
        "  historico.append({\"parts\":[resposta],\"role\":\"model\"})\n"
      ],
      "metadata": {
        "id": "uREGHOWWCYZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}